<!DOCTYPE html>
<html lang="en">
<head>
     <meta charset="UTF-8">
     <meta http-equiv="X-UA-Compatible" content="IE=edge">
     <meta name="viewport" content="width=device-width, initial-scale=1.0">
     <link rel="shortcut icon" href="../../source/lang-favicon.png" type="image/x-icon">
     <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css" integrity="sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==" crossorigin="anonymous" referrerpolicy="no-referrer" />
     <link rel="stylesheet" href="../../source/style.css">
     <link rel="stylesheet" href="../../source/prism.css">
     <meta name="description" content="Web scraping is the process of extracting data from websites. Python provides several powerful libraries for web scraping, including BeautifulSoup and Scrapy.">
     <title>Web Scraping with Python</title>
</head>
<body>
     <!--Navigation Bar-->
     <header>
          <nav>
               <div class="menu">
                    <h2><a href="../../index.html" class="logo">LangGuides</a></h2>
                    <i class="fa-solid fa-bars" id="open"></i>
                    <i class="fa-solid fa-xmark" id="close"></i>
                 </div>
               <ul class="nav-links">
                    <a href="../../programming/programming-tutorials.html"><li>Programming</li></a>
                    <a href="../../jobinterview/interview-questions.html"><li>Job Interview</li></a>
                    <a href="../../biography/biography-stories.html"><li>Biography</li></a>
                    <a href="../../successstories/sucesss-stories.html"><li>Success Stories</li></a>
                    
                    <a href="../../top10/top10.html"><li>Top 10</li></a>
               </ul>
          </nav>
     </header>

     

     <i class="fa-solid fa-arrow-up" id="up"></i> 
<main> 
<section class="content">
<h1>Web Scraping with Python</h1>
<p>Web scraping is the process of extracting data from websites. Python provides several powerful libraries for web scraping, including BeautifulSoup and Scrapy.</p>
 

<article>

<h2>BeautifulSoup</h2>
<p>BeautifulSoup is a Python library for parsing HTML and XML documents. It allows you to navigate and search the document structure to extract the desired data.
</p>
<pre><code class="language-py">
from bs4 import BeautifulSoup
import requests

# Send a GET request to the website
url = "https://www.webdevmonk.com"
response = requests.get(url)

# Create a BeautifulSoup object
soup = BeautifulSoup(response.text, "html.parser")

# Find elements in the document
title = soup.find("title").text
print("Title:", title)

# Find all instances of a specific element
links = soup.find_all("a")
for link in links:
     print("Link:", link["href"])

# Extract data from specific CSS classes or IDs
data = soup.select(".class-name")
for item in data:
     print("Data:", item.text)

# Output
'''
Title: webdevmonk
Link: ./index.html
Link: ./tutorials/tutorials-main-page.html
Link: ./projects/projects-main-page.html
Link: ./tutorials/computer-programming-all-concepts.html
Link: ./tutorials/learn-python-in-45-minutes.html
Link: ./tutorials/java-tutorial-in-45minutes.html
Link: ./tutorials/c-tutorial-in-45minutes.html
Link: ./tutorials/cpp-tutorial-in-45minutes.html
Link: ./tutorials/csharp-tutorial-in-45minutes.html
Link: ./tutorials/dart-tutorial-in-45minutes.html
Link: ./tutorials/html-tutorial-in-45minutes.html
Link: ./tutorials/css-tutorial-in-45minutes.html
Link: ./tutorials/js-tutorial-in-45minutes.html
Link: ./tutorials/reactjs-tutorial-in-45minutes.html
Link: ./tutorials/flutter-tutorial-in-45minutes.html
Link: ./projects/notes-app-project.html
Link: ./projects/flip-color-project.html
Link: ./projects/tip-generator-project.html
Link: ./projects/simple-chatbot-project.html
Link: ./projects/password-generator.html
Link: ./projects/form-validator-project.html
Link: ./projects/rock-paper-scissors-project.html
Link: ./projects/time-application-project.html
Link: ./projects/random-quote-project.html
Link: ./projects/to-do-project.html
Link: ./index.html
Link: ./tutorials/tutorials-main-page.html
Link: ./projects/projects-main-page.html
Link: webdevmonk.feedback@gmail.com
Link: ./about/privacy-policy-webdevmonk.html
Link: ./about/terms-of-use-webdevmonk.html
'''
</code></pre>
<p>In this code, we send a GET request to a website, retrieve the HTML content, and create a BeautifulSoup object to parse the document. We can then use various methods like find(), find_all(), and select() to locate specific elements or extract data based on CSS classes or IDs.
</p>

<h2>Scrapy</h2>
<p>Scrapy is a powerful and flexible framework for web scraping. It provides a complete set of tools for crawling websites, following links, and extracting structured data.
</p>
<p>Command to install Scrapy</p>
<pre><code class="language-py">pip install scrapy
</code></pre>

<pre><code class="language-py">
import scrapy

class MySpider(scrapy.Spider):
     name = "example_spider"
     start_urls = ["https://www.webdevmonk.com"]

     def parse(self, response):
          # Extract data from the response
          title = response.css("title::text").get()
          print("Title:", title)

          # Extract data from specific CSS selectors
          links = response.css("a::attr(href)").getall()
          for link in links:
               print("Link:", link)

          # Follow links to other pages
          yield from response.follow_all(css=".class-name a::attr(href)", callback=self.parse_other_page)

     def parse_other_page(self, response):
          # Extract data from other pages
          data = response.css(".other-class::text").get()
          print("Data:", data)
</code></pre>
<p>In this code, we define a Scrapy spider by creating a class that inherits from scrapy.Spider. We specify the starting URLs and define the parse() method to extract data from the response. We can use CSS selectors with the response.css() method to locate elements and extract data. We can also follow links to other pages using response.follow() or response.follow_all().
</p>

</article>

<div class="prev-next">
     <a href="./python-database.html" class="next">Previous</a>
     <a href="./python-faqs.html" class="next">Next</a>
</div>

</section>

</main>

<footer>
     <h3><a href="../../index.html" class="logo">LangGuides</a></h3>
     <p>Copyright &#169;	 2023 langguides. All rights reserved</p>
     <a href="../../about/privacy.html">Privacy Policy</a>
     <a href="../../about/terms-of-use.html">Terms of Use</a>
</footer>

<script src="../../source/index.js"></script>
<script src="../../source/prism.js"></script>
</body>
</html>